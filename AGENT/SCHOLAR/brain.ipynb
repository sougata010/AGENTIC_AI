{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SCHOLAR - Scientific Comprehensive Holistic Objective Learning And Research\n",
                "## Full Academic Research Workflow Platform\n",
                "\n",
                "**Complete Research Pipeline:**\n",
                "1. **SURVEY** - Systematic Literature Review & Gap Analysis\n",
                "2. **HYPOTHESIS** - Research Question & Hypothesis Generation\n",
                "3. **METHOD** - Methodology Design & Experimental Planning\n",
                "4. **ANALYZE** - Statistical Analysis & Data Interpretation\n",
                "5. **WRITE** - Academic Paper Drafting & Structure\n",
                "6. **REVIEW** - Peer Review Simulation & Critique\n",
                "7. **CITE** - Citation Management & Bibliography"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from dotenv import load_dotenv\n",
                "from pydantic import BaseModel, Field\n",
                "from typing import List, Optional, Dict\n",
                "from datetime import datetime\n",
                "from xhtml2pdf import pisa\n",
                "import os, json, hashlib\n",
                "\n",
                "load_dotenv()\n",
                "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0.4)\n",
                "\n",
                "class Config:\n",
                "    DATA = 'scholar_data'\n",
                "    REPORTS = f'{DATA}/papers'\n",
                "    REVIEWS = f'{DATA}/reviews'\n",
                "    PROJECTS = f'{DATA}/projects'\n",
                "\n",
                "for d in [Config.DATA, Config.REPORTS, Config.REVIEWS, Config.PROJECTS]: os.makedirs(d, exist_ok=True)\n",
                "\n",
                "CSS = '''<style>\n",
                "@page{size:A4;margin:2.5cm}body{font-family:\"Times New Roman\",Georgia,serif;font-size:11pt;line-height:1.8;color:#1a1a1a;text-align:justify}\n",
                ".header{text-align:center;margin-bottom:30px;border-bottom:2px solid #1a237e;padding-bottom:20px}\n",
                ".header h1{font-size:16pt;margin:0 0 10px 0;color:#1a237e}.header .meta{font-size:10pt;color:#666}\n",
                "h2{font-size:13pt;color:#1a237e;margin-top:25px;border-bottom:1px solid #e0e0e0;padding-bottom:5px}\n",
                "h3{font-size:11pt;color:#37474f;margin-top:15px}\n",
                ".abstract{background:#f5f5f5;padding:15px;border-left:4px solid #1a237e;margin:20px 0;font-style:italic}\n",
                ".keyword{display:inline-block;background:#e3f2fd;padding:3px 10px;margin:2px;border-radius:15px;font-size:9pt}\n",
                ".finding{background:#e8f5e9;padding:12px;margin:10px 0;border-radius:4px;border-left:4px solid #4caf50}\n",
                ".gap{background:#fff3e0;padding:12px;margin:10px 0;border-radius:4px;border-left:4px solid #ff9800}\n",
                ".critical{background:#ffebee;padding:12px;margin:10px 0;border-radius:4px;border-left:4px solid #f44336}\n",
                ".info{background:#e3f2fd;padding:12px;margin:10px 0;border-radius:4px;border-left:4px solid #2196f3}\n",
                "table{width:100%;border-collapse:collapse;margin:15px 0;font-size:10pt}\n",
                "th{background:#1a237e;color:white;padding:10px;text-align:left}td{padding:10px;border:1px solid #e0e0e0}\n",
                "tr:nth-child(even){background:#fafafa}\n",
                ".ref{font-size:9pt;color:#666;margin:3px 0;padding-left:20px;text-indent:-20px}\n",
                ".score{text-align:center;font-size:28pt;font-weight:700;color:#1a237e;padding:15px}\n",
                ".footer{margin-top:30px;padding-top:15px;border-top:1px solid #ccc;font-size:8pt;color:#666;text-align:center}\n",
                "</style>'''\n",
                "\n",
                "class Project:\n",
                "    @staticmethod\n",
                "    def save(name, data):\n",
                "        with open(f'{Config.PROJECTS}/{name}.json', 'w') as f: json.dump(data, f, indent=2, default=str)\n",
                "    @staticmethod\n",
                "    def load(name):\n",
                "        path = f'{Config.PROJECTS}/{name}.json'\n",
                "        return json.load(open(path)) if os.path.exists(path) else None\n",
                "    @staticmethod\n",
                "    def list_all():\n",
                "        return [f.replace('.json', '') for f in os.listdir(Config.PROJECTS) if f.endswith('.json')]\n",
                "\n",
                "def pdf(html, folder, name):\n",
                "    ts = datetime.now()\n",
                "    footer = f'<div class=\"footer\">Generated by SCHOLAR | {ts.strftime(\"%Y-%m-%d %H:%M\")} | ID: {hashlib.md5(html.encode()).hexdigest()[:8]}</div>'\n",
                "    path = f'{Config.DATA}/{folder}/{name}_{ts.strftime(\"%Y%m%d_%H%M%S\")}.pdf'\n",
                "    with open(path, 'wb') as f: pisa.CreatePDF(CSS + html + footer, dest=f)\n",
                "    print(f'PDF: {path}')\n",
                "    return path\n",
                "\n",
                "print('SCHOLAR Core Initialized')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SURVEY MODULE - Systematic Literature Review\n",
                "\n",
                "class Paper(BaseModel):\n",
                "    title: str\n",
                "    authors: str\n",
                "    year: int\n",
                "    venue: str\n",
                "    key_findings: List[str]\n",
                "    methodology: str\n",
                "    limitations: List[str]\n",
                "    relevance: int = Field(ge=1, le=10)\n",
                "\n",
                "class Theme(BaseModel):\n",
                "    name: str\n",
                "    description: str\n",
                "    key_papers: List[str]\n",
                "    consensus: str\n",
                "    debates: List[str]\n",
                "\n",
                "class LiteratureReview(BaseModel):\n",
                "    topic: str\n",
                "    search_strategy: str\n",
                "    inclusion_criteria: List[str]\n",
                "    papers_analyzed: int\n",
                "    date_range: str\n",
                "    themes: List[Theme]\n",
                "    methodological_trends: List[str]\n",
                "    theoretical_frameworks: List[str]\n",
                "    research_gaps: List[str]\n",
                "    future_directions: List[str]\n",
                "    key_papers: List[Paper]\n",
                "\n",
                "class GapAnalysis(BaseModel):\n",
                "    field: str\n",
                "    current_state: str\n",
                "    gaps: List[Dict[str, str]]\n",
                "    opportunities: List[str]\n",
                "    barriers: List[str]\n",
                "    priority_ranking: List[str]\n",
                "\n",
                "SURVEY_PROMPT = '''You are a senior academic researcher conducting systematic literature reviews.\n",
                "Follow PRISMA guidelines. Be rigorous, comprehensive, and cite real research trends.\n",
                "Identify genuine gaps and future directions based on current state of research.'''\n",
                "\n",
                "class SURVEY:\n",
                "    def review(self, topic: str, scope: str = 'comprehensive') -> LiteratureReview:\n",
                "        prompt = ChatPromptTemplate.from_messages([('system', SURVEY_PROMPT), ('human', 'Systematic literature review on: {topic}\\nScope: {scope}')])\n",
                "        r = (prompt | model.with_structured_output(LiteratureReview)).invoke({'topic': topic, 'scope': scope})\n",
                "        \n",
                "        themes_html = ''.join([f'''<div class=\"info\"><h3>{t.name}</h3><p>{t.description}</p>\n",
                "        <p><strong>Key Papers:</strong> {', '.join(t.key_papers)}</p>\n",
                "        <p><strong>Consensus:</strong> {t.consensus}</p>\n",
                "        <p><strong>Debates:</strong> {''.join([f'<br>- {d}' for d in t.debates])}</p></div>''' for t in r.themes])\n",
                "        \n",
                "        papers_html = ''.join([f'''<tr><td>{p.title}</td><td>{p.authors}</td><td>{p.year}</td><td>{p.venue}</td><td>{p.relevance}/10</td></tr>''' for p in r.key_papers])\n",
                "        \n",
                "        html = f'''<div class=\"header\"><h1>Systematic Literature Review</h1><div class=\"meta\">{r.topic}</div></div>\n",
                "        <div class=\"abstract\"><strong>Search Strategy:</strong> {r.search_strategy}<br>\n",
                "        <strong>Date Range:</strong> {r.date_range} | <strong>Papers Analyzed:</strong> {r.papers_analyzed}</div>\n",
                "        <h2>Inclusion Criteria</h2><ul>{''.join([f'<li>{c}</li>' for c in r.inclusion_criteria])}</ul>\n",
                "        <h2>Thematic Analysis</h2>{themes_html}\n",
                "        <h2>Methodological Trends</h2><ul>{''.join([f'<li>{m}</li>' for m in r.methodological_trends])}</ul>\n",
                "        <h2>Theoretical Frameworks</h2><ul>{''.join([f'<li>{t}</li>' for t in r.theoretical_frameworks])}</ul>\n",
                "        <h2>Research Gaps</h2>{''.join([f'<div class=\"gap\">{g}</div>' for g in r.research_gaps])}\n",
                "        <h2>Future Directions</h2>{''.join([f'<div class=\"finding\">{d}</div>' for d in r.future_directions])}\n",
                "        <h2>Key Papers</h2><table><tr><th>Title</th><th>Authors</th><th>Year</th><th>Venue</th><th>Relevance</th></tr>{papers_html}</table>'''\n",
                "        \n",
                "        print(f'Review: {r.topic} | {r.papers_analyzed} papers | {len(r.themes)} themes | {len(r.research_gaps)} gaps')\n",
                "        pdf(html, 'reviews', f'lit_review_{topic.replace(\" \", \"_\")[:30]}')\n",
                "        return r\n",
                "    \n",
                "    def gaps(self, field: str) -> GapAnalysis:\n",
                "        prompt = ChatPromptTemplate.from_messages([('system', SURVEY_PROMPT), ('human', 'Research gap analysis for: {field}')])\n",
                "        r = (prompt | model.with_structured_output(GapAnalysis)).invoke({'field': field})\n",
                "        \n",
                "        gaps_html = ''.join([f'''<div class=\"gap\"><h3>{g.get('gap', 'Gap')}</h3>\n",
                "        <p><strong>Type:</strong> {g.get('type', 'N/A')} | <strong>Priority:</strong> {g.get('priority', 'Medium')}</p>\n",
                "        <p>{g.get('description', '')}</p></div>''' for g in r.gaps])\n",
                "        \n",
                "        html = f'''<div class=\"header\"><h1>Research Gap Analysis</h1><div class=\"meta\">{r.field}</div></div>\n",
                "        <h2>Current State of Knowledge</h2><div class=\"info\">{r.current_state}</div>\n",
                "        <h2>Identified Gaps</h2>{gaps_html}\n",
                "        <h2>Research Opportunities</h2>{''.join([f'<div class=\"finding\">{o}</div>' for o in r.opportunities])}\n",
                "        <h2>Barriers to Progress</h2>{''.join([f'<div class=\"critical\">{b}</div>' for b in r.barriers])}\n",
                "        <h2>Priority Ranking</h2><ol>{''.join([f'<li><strong>{p}</strong></li>' for p in r.priority_ranking])}</ol>'''\n",
                "        \n",
                "        print(f'Gaps: {r.field} | {len(r.gaps)} gaps | {len(r.opportunities)} opportunities')\n",
                "        pdf(html, 'reviews', f'gap_analysis_{field.replace(\" \", \"_\")[:30]}')\n",
                "        return r\n",
                "\n",
                "survey = SURVEY()\n",
                "print('SURVEY Module Ready')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# HYPOTHESIS MODULE - Research Questions & Hypotheses\n",
                "\n",
                "class ResearchQuestion(BaseModel):\n",
                "    question: str\n",
                "    type: str = Field(description='Descriptive/Exploratory/Explanatory/Causal')\n",
                "    variables: List[str]\n",
                "    theoretical_basis: str\n",
                "    novelty: str\n",
                "    feasibility: int = Field(ge=1, le=10)\n",
                "    impact: int = Field(ge=1, le=10)\n",
                "\n",
                "class Hypothesis(BaseModel):\n",
                "    statement: str\n",
                "    null_hypothesis: str\n",
                "    alternative_hypothesis: str\n",
                "    independent_variable: str\n",
                "    dependent_variable: str\n",
                "    control_variables: List[str]\n",
                "    predicted_direction: str\n",
                "    theoretical_rationale: str\n",
                "    testability: int = Field(ge=1, le=10)\n",
                "\n",
                "class ResearchDesign(BaseModel):\n",
                "    title: str\n",
                "    problem_statement: str\n",
                "    research_questions: List[ResearchQuestion]\n",
                "    hypotheses: List[Hypothesis]\n",
                "    theoretical_framework: str\n",
                "    contribution: str\n",
                "    scope: str\n",
                "    limitations: List[str]\n",
                "\n",
                "HYPOTHESIS_PROMPT = '''You are a research methodologist helping design rigorous research.\n",
                "Generate testable hypotheses with clear operationalization.\n",
                "Ensure theoretical grounding and practical feasibility.'''\n",
                "\n",
                "class HYPOTHESIS:\n",
                "    def design(self, topic: str, gap: str = '') -> ResearchDesign:\n",
                "        prompt = ChatPromptTemplate.from_messages([('system', HYPOTHESIS_PROMPT), ('human', 'Design research for: {topic}\\nAddressing gap: {gap}')])\n",
                "        r = (prompt | model.with_structured_output(ResearchDesign)).invoke({'topic': topic, 'gap': gap})\n",
                "        \n",
                "        rqs = ''.join([f'''<div class=\"info\"><h3>RQ{i+1}: {q.question}</h3>\n",
                "        <p><span class=\"keyword\">{q.type}</span> <span class=\"keyword\">Feasibility: {q.feasibility}/10</span> <span class=\"keyword\">Impact: {q.impact}/10</span></p>\n",
                "        <p><strong>Variables:</strong> {', '.join(q.variables)}</p>\n",
                "        <p><strong>Theoretical Basis:</strong> {q.theoretical_basis}</p>\n",
                "        <p><strong>Novelty:</strong> {q.novelty}</p></div>''' for i, q in enumerate(r.research_questions)])\n",
                "        \n",
                "        hyps = ''.join([f'''<div class=\"finding\"><h3>H{i+1}: {h.statement}</h3>\n",
                "        <table><tr><td><strong>H₀:</strong></td><td>{h.null_hypothesis}</td></tr>\n",
                "        <tr><td><strong>H₁:</strong></td><td>{h.alternative_hypothesis}</td></tr>\n",
                "        <tr><td><strong>IV:</strong></td><td>{h.independent_variable}</td></tr>\n",
                "        <tr><td><strong>DV:</strong></td><td>{h.dependent_variable}</td></tr>\n",
                "        <tr><td><strong>Controls:</strong></td><td>{', '.join(h.control_variables)}</td></tr></table>\n",
                "        <p><strong>Rationale:</strong> {h.theoretical_rationale}</p>\n",
                "        <p><span class=\"keyword\">Testability: {h.testability}/10</span></p></div>''' for i, h in enumerate(r.hypotheses)])\n",
                "        \n",
                "        html = f'''<div class=\"header\"><h1>{r.title}</h1><div class=\"meta\">Research Design Document</div></div>\n",
                "        <h2>Problem Statement</h2><div class=\"abstract\">{r.problem_statement}</div>\n",
                "        <h2>Research Questions</h2>{rqs}\n",
                "        <h2>Hypotheses</h2>{hyps}\n",
                "        <h2>Theoretical Framework</h2><div class=\"info\">{r.theoretical_framework}</div>\n",
                "        <h2>Expected Contribution</h2><div class=\"finding\">{r.contribution}</div>\n",
                "        <h2>Scope</h2><p>{r.scope}</p>\n",
                "        <h2>Limitations</h2><ul>{''.join([f'<li>{l}</li>' for l in r.limitations])}</ul>'''\n",
                "        \n",
                "        print(f'Design: {r.title} | {len(r.research_questions)} RQs | {len(r.hypotheses)} hypotheses')\n",
                "        pdf(html, 'papers', f'research_design_{topic.replace(\" \", \"_\")[:30]}')\n",
                "        return r\n",
                "\n",
                "hypothesis = HYPOTHESIS()\n",
                "print('HYPOTHESIS Module Ready')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# METHOD MODULE - Methodology Design\n",
                "\n",
                "class SampleDesign(BaseModel):\n",
                "    population: str\n",
                "    sampling_method: str\n",
                "    sample_size: int\n",
                "    power_analysis: str\n",
                "    inclusion_criteria: List[str]\n",
                "    exclusion_criteria: List[str]\n",
                "\n",
                "class Instrument(BaseModel):\n",
                "    name: str\n",
                "    type: str\n",
                "    reliability: str\n",
                "    validity: str\n",
                "    source: str\n",
                "\n",
                "class Procedure(BaseModel):\n",
                "    phase: str\n",
                "    description: str\n",
                "    duration: str\n",
                "    materials: List[str]\n",
                "\n",
                "class Methodology(BaseModel):\n",
                "    research_paradigm: str\n",
                "    approach: str = Field(description='Quantitative/Qualitative/Mixed')\n",
                "    design: str\n",
                "    sample: SampleDesign\n",
                "    instruments: List[Instrument]\n",
                "    procedure: List[Procedure]\n",
                "    data_collection: str\n",
                "    analysis_plan: List[str]\n",
                "    ethical_considerations: List[str]\n",
                "    limitations: List[str]\n",
                "    timeline: str\n",
                "\n",
                "METHOD_PROMPT = '''You are a research methodologist designing rigorous studies.\n",
                "Follow best practices for the chosen paradigm (quantitative, qualitative, mixed).\n",
                "Ensure validity, reliability, and ethical compliance.'''\n",
                "\n",
                "class METHOD:\n",
                "    def design(self, rq: str, approach: str = 'quantitative') -> Methodology:\n",
                "        prompt = ChatPromptTemplate.from_messages([('system', METHOD_PROMPT), ('human', 'Design {approach} methodology for RQ: {rq}')])\n",
                "        r = (prompt | model.with_structured_output(Methodology)).invoke({'rq': rq, 'approach': approach})\n",
                "        \n",
                "        instruments = ''.join([f'<tr><td>{i.name}</td><td>{i.type}</td><td>{i.reliability}</td><td>{i.validity}</td><td>{i.source}</td></tr>' for i in r.instruments])\n",
                "        procedures = ''.join([f'''<div class=\"info\"><h3>{p.phase}</h3>\n",
                "        <p>{p.description}</p>\n",
                "        <p><strong>Duration:</strong> {p.duration} | <strong>Materials:</strong> {', '.join(p.materials)}</p></div>''' for p in r.procedure])\n",
                "        \n",
                "        html = f'''<div class=\"header\"><h1>Research Methodology</h1><div class=\"meta\">{r.approach} | {r.design}</div></div>\n",
                "        <h2>Research Paradigm</h2><div class=\"info\">{r.research_paradigm}</div>\n",
                "        <h2>Sampling</h2>\n",
                "        <table><tr><td>Population</td><td>{r.sample.population}</td></tr>\n",
                "        <tr><td>Method</td><td>{r.sample.sampling_method}</td></tr>\n",
                "        <tr><td>Sample Size</td><td>n = {r.sample.sample_size}</td></tr>\n",
                "        <tr><td>Power Analysis</td><td>{r.sample.power_analysis}</td></tr></table>\n",
                "        <p><strong>Inclusion:</strong> {', '.join(r.sample.inclusion_criteria)}</p>\n",
                "        <p><strong>Exclusion:</strong> {', '.join(r.sample.exclusion_criteria)}</p>\n",
                "        <h2>Instruments</h2><table><tr><th>Name</th><th>Type</th><th>Reliability</th><th>Validity</th><th>Source</th></tr>{instruments}</table>\n",
                "        <h2>Procedure</h2>{procedures}\n",
                "        <h2>Data Collection</h2><div class=\"info\">{r.data_collection}</div>\n",
                "        <h2>Analysis Plan</h2><ol>{''.join([f'<li>{a}</li>' for a in r.analysis_plan])}</ol>\n",
                "        <h2>Ethical Considerations</h2><ul>{''.join([f'<li>{e}</li>' for e in r.ethical_considerations])}</ul>\n",
                "        <h2>Timeline</h2><p>{r.timeline}</p>\n",
                "        <h2>Limitations</h2><ul>{''.join([f'<li>{l}</li>' for l in r.limitations])}</ul>'''\n",
                "        \n",
                "        print(f'Methodology: {r.approach} {r.design} | n={r.sample.sample_size} | {len(r.instruments)} instruments')\n",
                "        pdf(html, 'papers', 'methodology')\n",
                "        return r\n",
                "\n",
                "method = METHOD()\n",
                "print('METHOD Module Ready')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ANALYZE MODULE - Statistical Analysis\n",
                "\n",
                "class StatisticalTest(BaseModel):\n",
                "    test: str\n",
                "    purpose: str\n",
                "    assumptions: List[str]\n",
                "    interpretation: str\n",
                "    effect_size: str\n",
                "    code: str\n",
                "\n",
                "class AnalysisPlan(BaseModel):\n",
                "    research_question: str\n",
                "    variables: Dict[str, str]\n",
                "    preliminary_tests: List[str]\n",
                "    main_analyses: List[StatisticalTest]\n",
                "    post_hoc: List[str]\n",
                "    reporting_guidelines: str\n",
                "    visualization: List[str]\n",
                "\n",
                "class ResultsInterpretation(BaseModel):\n",
                "    findings: List[str]\n",
                "    statistical_summary: str\n",
                "    effect_sizes: List[str]\n",
                "    practical_significance: str\n",
                "    limitations: List[str]\n",
                "    implications: List[str]\n",
                "\n",
                "ANALYZE_PROMPT = '''You are a statistician and data analyst.\n",
                "Recommend appropriate statistical tests based on research design.\n",
                "Provide Python/R code, effect sizes, and proper interpretation guidelines.'''\n",
                "\n",
                "class ANALYZE:\n",
                "    def plan(self, rq: str, variables: str, design: str) -> AnalysisPlan:\n",
                "        prompt = ChatPromptTemplate.from_messages([('system', ANALYZE_PROMPT), ('human', 'Analysis plan for:\\nRQ: {rq}\\nVariables: {vars}\\nDesign: {design}')])\n",
                "        r = (prompt | model.with_structured_output(AnalysisPlan)).invoke({'rq': rq, 'vars': variables, 'design': design})\n",
                "        \n",
                "        tests = ''.join([f'''<div class=\"info\"><h3>{t.test}</h3>\n",
                "        <p><strong>Purpose:</strong> {t.purpose}</p>\n",
                "        <p><strong>Assumptions:</strong> {', '.join(t.assumptions)}</p>\n",
                "        <p><strong>Effect Size:</strong> {t.effect_size}</p>\n",
                "        <div style=\"background:#263238;color:#b2ff59;padding:10px;font-family:monospace;font-size:9pt;border-radius:4px\">{t.code.replace('<', '&lt;')}</div>\n",
                "        <p><strong>Interpretation:</strong> {t.interpretation}</p></div>''' for t in r.main_analyses])\n",
                "        \n",
                "        html = f'''<div class=\"header\"><h1>Statistical Analysis Plan</h1></div>\n",
                "        <h2>Research Question</h2><div class=\"abstract\">{r.research_question}</div>\n",
                "        <h2>Variables</h2><table>{''.join([f'<tr><td><strong>{k}</strong></td><td>{v}</td></tr>' for k, v in r.variables.items()])}</table>\n",
                "        <h2>Preliminary Tests</h2><ul>{''.join([f'<li>{t}</li>' for t in r.preliminary_tests])}</ul>\n",
                "        <h2>Main Analyses</h2>{tests}\n",
                "        <h2>Post-hoc Tests</h2><ul>{''.join([f'<li>{p}</li>' for p in r.post_hoc])}</ul>\n",
                "        <h2>Visualization</h2><ul>{''.join([f'<li>{v}</li>' for v in r.visualization])}</ul>\n",
                "        <h2>Reporting Guidelines</h2><div class=\"finding\">{r.reporting_guidelines}</div>'''\n",
                "        \n",
                "        print(f'Analysis Plan | {len(r.main_analyses)} tests | {len(r.visualization)} visualizations')\n",
                "        pdf(html, 'papers', 'analysis_plan')\n",
                "        return r\n",
                "    \n",
                "    def interpret(self, results: str, context: str) -> ResultsInterpretation:\n",
                "        prompt = ChatPromptTemplate.from_messages([('system', ANALYZE_PROMPT), ('human', 'Interpret results:\\n{results}\\nContext: {context}')])\n",
                "        r = (prompt | model.with_structured_output(ResultsInterpretation)).invoke({'results': results, 'context': context})\n",
                "        \n",
                "        html = f'''<div class=\"header\"><h1>Results Interpretation</h1></div>\n",
                "        <h2>Key Findings</h2>{''.join([f'<div class=\"finding\">{f}</div>' for f in r.findings])}\n",
                "        <h2>Statistical Summary</h2><div class=\"info\">{r.statistical_summary}</div>\n",
                "        <h2>Effect Sizes</h2><ul>{''.join([f'<li>{e}</li>' for e in r.effect_sizes])}</ul>\n",
                "        <h2>Practical Significance</h2><p>{r.practical_significance}</p>\n",
                "        <h2>Implications</h2><ul>{''.join([f'<li>{i}</li>' for i in r.implications])}</ul>\n",
                "        <h2>Limitations</h2><ul>{''.join([f'<li>{l}</li>' for l in r.limitations])}</ul>'''\n",
                "        \n",
                "        print(f'Interpretation | {len(r.findings)} findings | {len(r.implications)} implications')\n",
                "        pdf(html, 'papers', 'results_interpretation')\n",
                "        return r\n",
                "\n",
                "analyze = ANALYZE()\n",
                "print('ANALYZE Module Ready')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# WRITE MODULE - Academic Paper Drafting\n",
                "\n",
                "class Abstract(BaseModel):\n",
                "    background: str\n",
                "    objective: str\n",
                "    methods: str\n",
                "    results: str\n",
                "    conclusion: str\n",
                "    keywords: List[str]\n",
                "    word_count: int\n",
                "\n",
                "class Section(BaseModel):\n",
                "    title: str\n",
                "    content: str\n",
                "    subsections: List[Dict[str, str]]\n",
                "\n",
                "class PaperDraft(BaseModel):\n",
                "    title: str\n",
                "    abstract: Abstract\n",
                "    introduction: Section\n",
                "    literature_review: Section\n",
                "    methodology: Section\n",
                "    results: Section\n",
                "    discussion: Section\n",
                "    conclusion: Section\n",
                "    references: List[str]\n",
                "\n",
                "WRITE_PROMPT = '''You are an academic writing expert.\n",
                "Follow APA/IEEE style as appropriate. Write clearly, concisely, and rigorously.\n",
                "Ensure logical flow and proper academic tone.'''\n",
                "\n",
                "class WRITE:\n",
                "    def abstract(self, title: str, summary: str) -> Abstract:\n",
                "        prompt = ChatPromptTemplate.from_messages([('system', WRITE_PROMPT), ('human', 'Write structured abstract for:\\nTitle: {title}\\nSummary: {summary}')])\n",
                "        r = (prompt | model.with_structured_output(Abstract)).invoke({'title': title, 'summary': summary})\n",
                "        \n",
                "        html = f'''<div class=\"header\"><h1>{title}</h1></div>\n",
                "        <div class=\"abstract\"><strong>Background:</strong> {r.background}<br><br>\n",
                "        <strong>Objective:</strong> {r.objective}<br><br>\n",
                "        <strong>Methods:</strong> {r.methods}<br><br>\n",
                "        <strong>Results:</strong> {r.results}<br><br>\n",
                "        <strong>Conclusion:</strong> {r.conclusion}</div>\n",
                "        <p><strong>Keywords:</strong> {''.join([f'<span class=\"keyword\">{k}</span>' for k in r.keywords])}</p>\n",
                "        <p><em>Word count: {r.word_count}</em></p>'''\n",
                "        \n",
                "        print(f'Abstract | {r.word_count} words | {len(r.keywords)} keywords')\n",
                "        pdf(html, 'papers', 'abstract')\n",
                "        return r\n",
                "    \n",
                "    def section(self, section_name: str, context: str, guidelines: str = '') -> Section:\n",
                "        prompt = ChatPromptTemplate.from_messages([('system', WRITE_PROMPT), ('human', 'Write {section} section:\\nContext: {context}\\nGuidelines: {guidelines}')])\n",
                "        r = (prompt | model.with_structured_output(Section)).invoke({'section': section_name, 'context': context, 'guidelines': guidelines})\n",
                "        \n",
                "        subs = ''.join([f'<h3>{s.get(\"title\", \"\")}</h3><p>{s.get(\"content\", \"\")}</p>' for s in r.subsections])\n",
                "        html = f'''<div class=\"header\"><h1>{r.title}</h1></div>\n",
                "        <p>{r.content}</p>{subs}'''\n",
                "        \n",
                "        print(f'Section: {r.title} | {len(r.subsections)} subsections')\n",
                "        pdf(html, 'papers', f'section_{section_name}')\n",
                "        return r\n",
                "\n",
                "write = WRITE()\n",
                "print('WRITE Module Ready')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# REVIEW MODULE - Peer Review Simulation\n",
                "\n",
                "class ReviewCriterion(BaseModel):\n",
                "    criterion: str\n",
                "    score: int = Field(ge=1, le=10)\n",
                "    strengths: List[str]\n",
                "    weaknesses: List[str]\n",
                "    suggestions: List[str]\n",
                "\n",
                "class PeerReview(BaseModel):\n",
                "    summary: str\n",
                "    recommendation: str = Field(description='Accept/Minor Revisions/Major Revisions/Reject')\n",
                "    criteria: List[ReviewCriterion]\n",
                "    major_concerns: List[str]\n",
                "    minor_concerns: List[str]\n",
                "    questions_for_authors: List[str]\n",
                "    overall_score: int = Field(ge=1, le=10)\n",
                "\n",
                "REVIEW_PROMPT = '''You are a rigorous peer reviewer for top academic journals.\n",
                "Evaluate manuscripts critically but constructively.\n",
                "Focus on methodology, contribution, clarity, and validity.'''\n",
                "\n",
                "class REVIEW:\n",
                "    def review(self, manuscript: str, venue: str = 'top journal') -> PeerReview:\n",
                "        prompt = ChatPromptTemplate.from_messages([('system', REVIEW_PROMPT), ('human', 'Peer review for {venue}:\\n{manuscript}')])\n",
                "        r = (prompt | model.with_structured_output(PeerReview)).invoke({'manuscript': manuscript[:5000], 'venue': venue})\n",
                "        \n",
                "        criteria_html = ''.join([f'''<div class=\"{'finding' if c.score >= 7 else 'gap' if c.score >= 5 else 'critical'}\">\n",
                "        <h3>{c.criterion}: {c.score}/10</h3>\n",
                "        <p><strong>Strengths:</strong> {', '.join(c.strengths)}</p>\n",
                "        <p><strong>Weaknesses:</strong> {', '.join(c.weaknesses)}</p>\n",
                "        <p><strong>Suggestions:</strong> {', '.join(c.suggestions)}</p></div>''' for c in r.criteria])\n",
                "        \n",
                "        rec_color = {'Accept': 'finding', 'Minor Revisions': 'info', 'Major Revisions': 'gap', 'Reject': 'critical'}\n",
                "        \n",
                "        html = f'''<div class=\"header\"><h1>Peer Review Report</h1><div class=\"meta\">{venue}</div></div>\n",
                "        <div class=\"score\">{r.overall_score}/10</div>\n",
                "        <div class=\"{rec_color.get(r.recommendation, 'info')}\" style=\"text-align:center;font-size:14pt;font-weight:bold\">\n",
                "        Recommendation: {r.recommendation}</div>\n",
                "        <h2>Summary</h2><div class=\"abstract\">{r.summary}</div>\n",
                "        <h2>Evaluation Criteria</h2>{criteria_html}\n",
                "        <h2>Major Concerns</h2>{''.join([f'<div class=\"critical\">{c}</div>' for c in r.major_concerns])}\n",
                "        <h2>Minor Concerns</h2><ul>{''.join([f'<li>{c}</li>' for c in r.minor_concerns])}</ul>\n",
                "        <h2>Questions for Authors</h2><ol>{''.join([f'<li>{q}</li>' for q in r.questions_for_authors])}</ol>'''\n",
                "        \n",
                "        print(f'Review | {r.recommendation} | Score: {r.overall_score}/10')\n",
                "        pdf(html, 'reviews', 'peer_review')\n",
                "        return r\n",
                "\n",
                "review = REVIEW()\n",
                "print('REVIEW Module Ready')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SCHOLAR:\n",
                "    def __init__(self):\n",
                "        self.survey = survey\n",
                "        self.hypothesis = hypothesis\n",
                "        self.method = method\n",
                "        self.analyze = analyze\n",
                "        self.write = write\n",
                "        self.review = review\n",
                "    \n",
                "    def projects(self):\n",
                "        ps = Project.list_all()\n",
                "        print(f'\\n{len(ps)} Projects: {\", \".join(ps) if ps else \"None\"}')\n",
                "    \n",
                "    def help(self):\n",
                "        print('''\n",
                "SCHOLAR - Full Academic Research Platform\n",
                "==========================================\n",
                "\n",
                "SURVEY (Literature):\n",
                "  scholar.survey.review(topic)       Systematic lit review\n",
                "  scholar.survey.gaps(field)         Research gap analysis\n",
                "\n",
                "HYPOTHESIS (Design):\n",
                "  scholar.hypothesis.design(topic)   RQs & Hypotheses\n",
                "\n",
                "METHOD (Methodology):\n",
                "  scholar.method.design(rq)          Methodology design\n",
                "\n",
                "ANALYZE (Statistics):\n",
                "  scholar.analyze.plan(rq,vars,design) Analysis plan\n",
                "  scholar.analyze.interpret(results)   Interpret results\n",
                "\n",
                "WRITE (Drafting):\n",
                "  scholar.write.abstract(title,sum)  Write abstract\n",
                "  scholar.write.section(name,ctx)    Write section\n",
                "\n",
                "REVIEW (Peer Review):\n",
                "  scholar.review.review(manuscript)  Simulate peer review\n",
                "\n",
                "UTILITIES:\n",
                "  scholar.projects()                 List saved projects\n",
                "''')\n",
                "\n",
                "scholar = SCHOLAR()\n",
                "print('\\n' + '='*50)\n",
                "print('SCHOLAR READY - Run scholar.help()')\n",
                "print('='*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scholar.help()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scholar.survey.review('Deep Learning for Medical Image Analysis')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scholar.hypothesis.design('AI-assisted diagnosis accuracy', 'Lack of explainability in deep learning models')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scholar.method.design('Does explainable AI improve physician trust compared to black-box models?', 'quantitative')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scholar.analyze.plan('Effect of explainable AI on diagnostic accuracy', 'IV: AI type (XAI vs black-box), DV: accuracy, trust, adoption', 'Randomized controlled experiment')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scholar.write.abstract('Explainable AI in Medical Diagnosis: A Randomized Controlled Trial', 'Study comparing XAI vs black-box models for radiology diagnosis, measured physician trust, accuracy, and adoption rates')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scholar.review.review('This paper presents a study on explainable AI in medical imaging. We conducted an RCT with 120 radiologists comparing XAI and traditional deep learning models. Results show 23% improvement in trust and 15% improvement in diagnostic accuracy with XAI. The study has limitations including sample from single institution.')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}