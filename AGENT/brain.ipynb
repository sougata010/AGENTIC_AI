{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e6b1507c",
            "metadata": {},
            "source": [
                "# **LLM BRAIN**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "id": "99f0f1a0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "API KEY LOADED SUCCESSFULLY\n"
                    ]
                }
            ],
            "source": [
                "from dotenv import load_dotenv\n",
                "import os\n",
                "import json\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from functions import (\n",
                "    init_gemini_client, \n",
                "    generate_trending_topic, \n",
                "    generate_full_pin_concept, \n",
                "    PinterestPinStrategy, \n",
                "    log_to_daily_jsonl\n",
                ")\n",
                "from prompts import get_system_prompt\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "if os.environ.get('GEMINI_API_KEY'):\n",
                "    print(\"API KEY LOADED SUCCESSFULLY\")\n",
                "else:\n",
                "    raise AttributeError(\"API KEY NOT FOUND\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "432ec05d",
            "metadata": {},
            "source": [
                "# **EXECUTION**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "id": "399b98c6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generating Trending Topic...\n",
                        "Topic: Cozy Neutral Home Decor\n",
                        "Expanding Concept...\n",
                        "Generating Strategy JSON...\n",
                        "✅ Success! Strategy saved to logs\\2026-02-04_pinterest.jsonl\n"
                    ]
                }
            ],
            "source": [
                "client_creative = init_gemini_client(temperature=0.7)\n",
                "\n",
                "print(\"Generating Trending Topic...\")\n",
                "USER_PROMPT = generate_trending_topic(client_creative)\n",
                "print(f\"Topic: {USER_PROMPT}\")\n",
                "\n",
                "print(\"Expanding Concept...\")\n",
                "FULL_TOPIC = generate_full_pin_concept(client_creative, USER_PROMPT)\n",
                "\n",
                "model_structured = init_gemini_client(temperature=0, response_mime_type=\"application/json\")\n",
                "structured_llm = model_structured.with_structured_output(PinterestPinStrategy)\n",
                "\n",
                "prompt_template = ChatPromptTemplate.from_messages([\n",
                "    (\"system\", get_system_prompt()),\n",
                "    (\"human\", \"{topic}\")\n",
                "])\n",
                "chain = prompt_template | structured_llm\n",
                "\n",
                "try:\n",
                "    print(\"Generating Strategy JSON...\")\n",
                "    result = chain.invoke({'topic': FULL_TOPIC})\n",
                "\n",
                "    with open('current_strategy.json', 'w') as f:\n",
                "        if hasattr(result, 'model_dump'):\n",
                "             json.dump(result.model_dump(), f)\n",
                "        else:\n",
                "             json.dump(result.dict(), f)\n",
                "             \n",
                "    log_file = log_to_daily_jsonl(result, folder=\"logs\")\n",
                "    print(f\"✅ Success! Strategy saved to {log_file}\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"❌ Error: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
