import os
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from xhtml2pdf import pisa
from dotenv import load_dotenv

from app.agents.base import BaseAgent
from app.config import settings

load_dotenv()

DATA_DIR = settings.DATA_DIR / "career_data"
RESUME_DIR = DATA_DIR / "resumes"
DEBATE_DIR = DATA_DIR / "debates"

for d in [DATA_DIR, RESUME_DIR, DEBATE_DIR]:
    os.makedirs(d, exist_ok=True)

# --- PDF Helper ---
CSS = """<style>
@page{size:A4;margin:2cm}body{font-family:Helvetica,Arial,sans-serif;font-size:11pt;line-height:1.6;color:#333}
h1{color:#2c3e50;border-bottom:2px solid #3498db;padding-bottom:10px}
h2{color:#2980b9;margin-top:20px}
.box{background:#f8f9fa;padding:15px;border-left:5px solid #3498db;margin:10px 0;border-radius:4px}
.highlight{background:#fff3e0;padding:5px}
.footer{font-size:8pt;color:#7f8c8d;text-align:center;margin-top:30px;border-top:1px solid #ccc;padding-top:10px}
</style>"""

def create_pdf(html: str, folder: str, filename: str) -> str:
    path = DATA_DIR / folder / f"{filename}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
    with open(path, "wb") as f:
        pisa.CreatePDF(CSS + html + f'<div class="footer">Generated by Agentic AI - {datetime.now()}</div>', dest=f)
    print(f"ðŸ“„ PDF Generated: {path}")
    return str(path)

# --- Resume Optimizer Models ---
class ResumeAnalysis(BaseModel):
    score: int = Field(description="Score out of 100")
    summary: str
    missing_keywords: List[str]
    formatting_issues: List[str]
    rewritten_sections: List[Dict[str, str]] = Field(description="List of dicts with 'section' and 'content' keys")
    improvement_plan: List[str]

class ResumeAgent(BaseAgent):
    name = "resume_opt"
    description = "ATS Optimization & Resume Rewrite"
    icon = "ðŸ“„"

    async def execute(self, resume_text: str, job_description: str = "", **kwargs) -> Dict[str, Any]:
        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are an expert Resume Writer and ATS Specialist. Analyze the resume against the job description."),
            ("human", "Resume:\n{resume}\n\nJob Description:\n{job}")
        ])
        chain = prompt | self.model.with_structured_output(ResumeAnalysis)
        analysis = await self._safe_invoke(chain, {"resume": resume_text, "job": job_description})

        html = f"""
        <h1>Resume Analysis Report</h1>
        <div class="box">
            <h2>ATS Score: {analysis.score}/100</h2>
            <p>{analysis.summary}</p>
        </div>
        <h2>Missing Keywords</h2>
        <ul>{''.join([f'<li>{k}</li>' for k in analysis.missing_keywords])}</ul>
        
        <h2>Formatting Issues</h2>
        <ul>{''.join([f'<li>{i}</li>' for i in analysis.formatting_issues])}</ul>
        
        <h2>Recommended Rewrites</h2>
        {''.join([f'<div class="box"><h3>{s["section"]}</h3><p>{s["content"]}</p></div>' for s in analysis.rewritten_sections])}
        
        <h2>Action Plan</h2>
        <ul>{''.join([f'<li>{p}</li>' for p in analysis.improvement_plan])}</ul>
        """
        
        pdf_path = await asyncio.to_thread(create_pdf, html, "resumes", "resume_audit")
        return {"analysis": analysis.model_dump(), "pdf": pdf_path}

# --- Debate Coach Models ---
class DebateFeedback(BaseModel):
    winner_prediction: str
    logical_fallacies: List[str]
    strong_points: List[str]
    counter_arguments: List[str]
    closing_statement: str

class DebateAgent(BaseAgent):
    name = "debate_coach"
    description = "Logic Analysis & Negotiation Prep"
    icon = "âš–ï¸"

    async def execute(self, topic: str, user_argument: str, **kwargs) -> Dict[str, Any]:
        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a world-class Debate Coach. Analyze the user's argument, find flaws, and offer counter-arguments."),
            ("human", "Topic: {topic}\nMy Argument: {user_argument}")
        ])
        chain = prompt | self.model.with_structured_output(DebateFeedback)
        feedback = await self._safe_invoke(chain, {"topic": topic, "user_argument": user_argument})

        html = f"""
        <h1>Debate Coaching: {topic}</h1>
        <div class="box">
            <h2>Verdict: {feedback.winner_prediction}</h2>
            <p>{feedback.closing_statement}</p>
        </div>
        
        <h2>Logical Fallacies Detected</h2>
        <ul>{''.join([f'<li>{f}</li>' for f in feedback.logical_fallacies])}</ul>
        
        <h2>Your Strong Points</h2>
        <ul>{''.join([f'<li>{p}</li>' for p in feedback.strong_points])}</ul>
        
        <h2>Counter-Arguments</h2>
        {''.join([f'<div class="box"><p>{c}</p></div>' for c in feedback.counter_arguments])}
        """
        
        pdf_path = await asyncio.to_thread(create_pdf, html, "debates", topic.replace(" ", "_")[:20])
        return {"feedback": feedback.model_dump(), "pdf": pdf_path}
